pip install datasets rouge_score sentencepiece onnx onnx-graphsurgeon


import os
import sys
import random
import numpy as np
import torch
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from rouge_score import rouge_scorer

def main():
    # Load the dataset
    dataset = load_dataset('json', data_files={'train': 'train.json'})['train']

    # Set the random seed for reproducibility
    random.seed(42)
    np.random.seed(42)
    torch.manual_seed(42)

    # Define the model and tokenizer
    model_name = 't5-base'
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

    # Define the input and target columns
    input_column = 'input'
    target_column = 'target'

    # Preprocess the dataset
    def preprocess_function(examples):
        inputs = [example[input_column] for example in examples]
        targets = [example[target_column] for example in examples]

        inputs_tokenized = tokenizer(inputs, padding='longest', truncation=True, max_length=512)
        targets_tokenized = tokenizer(targets, padding='longest', truncation=True, max_length=512, return_tensors='pt')

        inputs_tokenized['input_ids'] = inputs_tokenized['input_ids'].to('cuda')
        inputs_tokenized['attention_mask'] = inputs_tokenized['attention_mask'].to('cuda')
        targets_tokenized['input_ids'] = targets_tokenized['input_ids'].to('cuda')
        targets_tokenized['attention_
